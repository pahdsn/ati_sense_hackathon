{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "SENSE CDT Practical Sentinel-1 Classification Problem Challenge - Template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hql5PBGB-j5x"
      },
      "source": [
        "# Automated Sentinel-1 Ice, Water, Land Segmentation Challenge\n",
        "\n",
        "\n",
        "\n",
        "This notebook is intended as a template only, to help guide through the training process. Feel free to use as little or as much of it as you like.\n",
        "\n",
        "For the purposes of the template, we will assume a *classification* approach, which involves sub-sampling small images from the Sentinel-1 images. There will be notes where code should be adjusted for a *segmentation* approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTTApq7Z-j54"
      },
      "source": [
        "### Dataset preparation - (1) sub-sampling\n",
        "\n",
        "Sample patches from each TIF image, and find the corresponding label using the Shapefiles. Save each image with a unique ID save in the directory **SAMPLING_DIR**. Save the corresponding meta data in the following format (this could be a CSV file, NumPy array, or some other format), in the directory **META_DIR**:\n",
        "\n",
        "\n",
        "```\n",
        "image_id, x, y, label\n",
        "```\n",
        "\n",
        "Set the label value as one of \"L\", \"W\", \"I\" as specified in the Shapefiles.\n",
        "\n",
        "To make it easier to patch the final segmentation back together, it is suggested to use the (x, y) pixel coordinates of the patch, rather than the spatial coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W2iHYwdWkFs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4usdTTQIWkMT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgtyqz-aWxgK"
      },
      "source": [
        "Mounting the drive n stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPlDhjkBWkOr"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "drive.mount('/content/drive')\r\n",
        "import os\r\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AujnfsBY-j55"
      },
      "source": [
        "SAMPLING_DIR = \"/content/drive/sampling\"\n",
        "META_DIR = \"/content/drive/training\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RiS75MeHiY7"
      },
      "source": [
        ""
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfuzctPH-mTv"
      },
      "source": [
        ""
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ7xvSM1EqgT"
      },
      "source": [
        ""
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S86TJAFXIFKi"
      },
      "source": [
        "import glob"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQvLsb7j-j55"
      },
      "source": [
        "Some helpful code: reading in a single Sentinel-1 image and the corresponding Shapefile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8fmOysu5-j56"
      },
      "source": [
        "# the directory containing all shapefiles - i.e., the location of sea_ice/ \n",
        "SHAPEFILE_DIR = \"/content/drive/My Drive/bloop/EE_Polar_Training_Dataset_v-1-0-0/Sea_Ice/\" \n",
        "TIFF_DIR = \"/content/drive/My Drive/bloop/Sentinel geotiffs\"\n",
        "\n",
        "shapefile = SHAPEFILE_DIR + \"seaice_s1_20180116t075430.shp\" # full name of .shp file\n",
        "\n",
        "# extract the shape ID, for example, 20180116T075430\n",
        "shp_id = shapefile.split(\"_\")[-1][:-4].upper()\n",
        "\n",
        "tiff_files = [g for g in glob.glob(TIFF_DIR+'/*.tif')]\n",
        "# locate the corresponding Sentinel-1 image based on the ID\n",
        "# this should only return 1 match, which you can confirm\n",
        "tiff_file = [g for g in tiff_files if shp_id in g]\n",
        "tiff_file = tiff_file[0]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UWaNJgv9KbjT",
        "outputId": "176c7814-6dbf-4464-ba5f-e4420c861860"
      },
      "source": [
        "tiff_file"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/bloop/Sentinel geotiffs/S1A_EW_GRDM_1SDH_20180116T075430_20180116T075530_020177_0226B9_9FE3_Orb_Cal_Spk_TC_rgb_8bit.tif'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m29VY8ZI-j56"
      },
      "source": [
        "Feel free to use other Python packages; but as an example, here we use **geopandas** to read in the Shapefile, and **rasterio** to read the GeoTIFF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QO4ZxeNKtHK",
        "outputId": "d07ddac7-8677-4874-f38f-95f85030c0d0"
      },
      "source": [
        "!apt-get install software-properties-common python-software-properties > /dev/null\r\n",
        "!add-apt-repository ppa:ubuntugis/ppa -y > /dev/null\r\n",
        "!apt-get update > /dev/null\r\n",
        "!apt-get install -y --fix-missing python-gdal gdal-bin libgdal-dev > /dev/null\r\n",
        "!pip2 install OpticalRS > /dev/null"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Extracting templates from packages: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSP3n5OoT88d"
      },
      "source": [
        "import gdal\r\n",
        "array = gdal.Open(tiff_file).ReadAsArray()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCubdvzvUECs",
        "outputId": "d350a66f-da31-46d7-a513-fd77a3d69ccb"
      },
      "source": [
        "array.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 15218, 15564)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eyKxFtqS-j57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4f8177c3-9d3a-41f2-fe69-e74a03b6da83"
      },
      "source": [
        "import geopandas as gpd\n",
        "#import rasterio\n",
        "\n",
        "shape_data = gpd.read_file(shapefile)\n",
        "\n",
        "shape_data.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>CA</th>\n",
              "      <th>SA</th>\n",
              "      <th>FA</th>\n",
              "      <th>CB</th>\n",
              "      <th>SB</th>\n",
              "      <th>FB</th>\n",
              "      <th>CT</th>\n",
              "      <th>poly_type</th>\n",
              "      <th>area</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>I</td>\n",
              "      <td>10797710</td>\n",
              "      <td>27049</td>\n",
              "      <td>POLYGON ((-489524.300 -1426091.270, -488551.97...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>W</td>\n",
              "      <td>77404396626</td>\n",
              "      <td>2078665</td>\n",
              "      <td>POLYGON ((-386420.098 -1661503.239, -386646.67...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>I</td>\n",
              "      <td>145176122</td>\n",
              "      <td>64674</td>\n",
              "      <td>POLYGON ((-485920.665 -1506863.657, -483911.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>L</td>\n",
              "      <td>10137</td>\n",
              "      <td>572</td>\n",
              "      <td>POLYGON ((-470402.672 -1412012.139, -470511.58...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>L</td>\n",
              "      <td>1284942354</td>\n",
              "      <td>277299</td>\n",
              "      <td>POLYGON ((-503153.134 -1606829.784, -503172.44...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  CA  ...  perimeter                                           geometry\n",
              "0   1  99  ...      27049  POLYGON ((-489524.300 -1426091.270, -488551.97...\n",
              "1   2  99  ...    2078665  POLYGON ((-386420.098 -1661503.239, -386646.67...\n",
              "2   3  99  ...      64674  POLYGON ((-485920.665 -1506863.657, -483911.10...\n",
              "3   4  99  ...        572  POLYGON ((-470402.672 -1412012.139, -470511.58...\n",
              "4   5  99  ...     277299  POLYGON ((-503153.134 -1606829.784, -503172.44...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2GEFLvoM8bU"
      },
      "source": [
        ""
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE9dgagxNi0D"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ETfZhxNuea"
      },
      "source": [
        "array = gdal.Open(tiff_file)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG5ZUOFFZu_z",
        "outputId": "81b0c436-6f22-4634-c32a-067eea498a3a"
      },
      "source": [
        "dataset=array\r\n",
        "\r\n",
        "print(\"Driver: {}/{}\".format(dataset.GetDriver().ShortName,\r\n",
        "                            dataset.GetDriver().LongName))\r\n",
        "print(\"Size is {} x {} x {}\".format(dataset.RasterXSize,\r\n",
        "                                    dataset.RasterYSize,\r\n",
        "                                    dataset.RasterCount))\r\n",
        "print(\"Projection is {}\".format(dataset.GetProjection()))\r\n",
        "geotransform = dataset.GetGeoTransform()\r\n",
        "if geotransform:\r\n",
        "    print(\"Origin = ({}, {})\".format(geotransform[0], geotransform[3]))\r\n",
        "    print(\"Pixel Size = ({}, {})\".format(geotransform[1], geotransform[5]))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Driver: GTiff/GeoTIFF\n",
            "Size is 15564 x 15218 x 3\n",
            "Projection is PROJCS[\"Stereographic / World Geodetic System 1984|\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Stereographic\"],PARAMETER[\"latitude_of_origin\",90],PARAMETER[\"central_meridian\",0],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]\n",
            "Origin = (-641345.5143141792, -1225812.3968040443)\n",
            "Pixel Size = (40.0, -40.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okqz3lgBOqpq"
      },
      "source": [
        "geotransform = array.GetGeoTransform()"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9wnafnDZQvV",
        "outputId": "09c12069-bbe0-4bfc-e320-220b71c28057"
      },
      "source": [
        "band = array.GetRasterBand(1)\r\n",
        "print(\"Band Type={}\".format(gdal.GetDataTypeName(band.DataType)))\r\n",
        "\r\n",
        "min = band.GetMinimum()\r\n",
        "max = band.GetMaximum()\r\n",
        "if not min or not max:\r\n",
        "    (min,max) = band.ComputeRasterMinMax(True)\r\n",
        "print(\"Min={:.3f}, Max={:.3f}\".format(min,max))\r\n",
        "\r\n",
        "if band.GetOverviewCount() > 0:\r\n",
        "    print(\"Band has {} overviews\".format(band.GetOverviewCount()))\r\n",
        "\r\n",
        "if band.GetRasterColorTable():\r\n",
        "    print(\"Band has a color table with {} entries\".format(band.GetRasterColorTable().GetCount()))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Band Type=Byte\n",
            "Min=1.000, Max=212.000\n",
            "Band has 8 overviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5XU12l0E-j57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "b5dae027-9f55-4b43-cd50-2bc7e1dce53f"
      },
      "source": [
        "# directory containing all GeoTIFF files\n",
        "\n",
        "tif_img = rasterio.open(TIFF_DIR + tiff_file)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-99-bf812e1b589a>\", line 3, in <module>\n",
            "    tif_img = rasterio.open(TIFF_DIR + tiff_file)\n",
            "NameError: name 'rasterio' is not defined\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8ofvGU4p-j57"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dmYXIql3-j58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MgWdkpo5-j58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFxw8tg6-j58"
      },
      "source": [
        "The shapes in the Shapefiles are **shapely** objects. We can also use the Python package **shapely** to check whether an x, y pixel coordinate position is in a given polyshape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FcoouG3z-j59"
      },
      "source": [
        "from shapely.geometry import Point\n",
        "\n",
        "x = 4000\n",
        "y = 8000\n",
        "\n",
        "point = Point(x, y)\n",
        "\n",
        "# for example, specify the shape in the Shapefile\n",
        "shape_id = 2\n",
        "\n",
        "if shape_data['geometry'][shape_id].contains(point):\n",
        "    print(\"Point\", point, \"is in shape\", shape_id, \"and has class\", shape_data['poly_type'][shape_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uJ94ww---j59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DmEb_nS5-j59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZCbWrV-j5-"
      },
      "source": [
        "Define a train/validation ratio. Patches and meta saved from the test TIF images should be stored in separate directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sDaJOga5-j5-"
      },
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "\n",
        "# valid size = 1.0 - TRAIN_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xuk-lWx-j5-"
      },
      "source": [
        "Map the class category characters to integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ikMewdT_-j5-"
      },
      "source": [
        "LABELS = {\n",
        "\t\"L\": 0,\n",
        "\t\"W\": 1,\n",
        "\t\"I\": 2,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWaVSu8H-j5_"
      },
      "source": [
        "The following is a Dataset class which reads in image data saved in the format described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Irb1P5YR-j5_"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class PolarPatch(Dataset):\n",
        "    def __init__(self, transform=None, split=\"train\"):\n",
        "        super(PolarPatch, self).__init__()\n",
        "\n",
        "        assert split in [\"train\", \"val\"]\n",
        "        \n",
        "        # TODO: load in meta data, which should be of shape (3, N) - N being the number of samples\n",
        "        meta = []\n",
        "\n",
        "        train_dim = int(TRAIN_SIZE * len(meta))\n",
        "        \n",
        "        if split == \"train\":\n",
        "            meta = meta[:train_dim]\n",
        "        else:\n",
        "            meta = meta[train_dim:]                   \n",
        "\n",
        "        self.images = range(len(meta))\n",
        "        self.coords = [(row[1], row[2]) for row in meta]\n",
        "\n",
        "        # Targets in integer form for computing cross entropy\n",
        "        self.targets = [LABELS[row[3]] for row in meta]\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        x = Image.open(SAMPLING_DIR + str(self.images[index]) + \".png\") # change this file format if needed\n",
        "        y = self.targets[index]\n",
        "        coord = self.coords[index]\n",
        "\n",
        "        if self.transform:\n",
        "        \tx = self.transform(x)\n",
        "\n",
        "        return x, y, coord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHLPTJL_-j5_"
      },
      "source": [
        "An example data transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tOK8djGd-j5_"
      },
      "source": [
        "data_transform = transforms.Compose([\n",
        "    # TODO: add whatever else you need - normalisation, augmentation, etc.\n",
        "\ttransforms.ToTensor(),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh3geoSw-j6A"
      },
      "source": [
        "### Dataset preparation - (2) data loaders\n",
        "\n",
        "Now we can prepare the data loaders. Here is the example for the training set; you will also need the validation and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mNMcldHn-j6A"
      },
      "source": [
        "import torch\n",
        "\n",
        "# TODO set this value based on your working environment\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_set = PolarPatch(\n",
        "    split='train',\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IUZRuStx-j6A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnhGcEjb-j6A"
      },
      "source": [
        "### Model\n",
        "\n",
        "You can use a custom model architecture, or copy one from literature. It is recommended to not build too deep of a network for the sake of training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lVIlwj_2-j6B"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class PolarNet(nn.Module):\n",
        "    def __init__(self, n_classes=3):\n",
        "        super(PolarNet, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # TODO: build your own architecture here; one conv layer and ReLU here as an example only\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True), \n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            # TODO: continue classifier section of architecture here for classification approach;\n",
        "            # otherwise, remove and add in upscaling for a fully-convolutional segmentation approach \n",
        "            nn.Linear(4096, n_classes),\n",
        "        )      \n",
        "\n",
        "    def forward(self, x):\n",
        "        # as an example; alter as needed depending on your architecture\n",
        "        x = self.features(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "K1fD76oG-j6B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "672EMF4J-j6C"
      },
      "source": [
        "### Training\n",
        "\n",
        "An example of loading the model, setting a loss criteria and defining an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "m929OqWl-j6C"
      },
      "source": [
        "# Device configuration - defaults to CPU unless GPU is available on device\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qIb_PScA-j6C"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "model = PolarNet().to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic gradient descent - TODO: alter as needed\n",
        "optimizer = optim.SGD(\n",
        "\tmodel.parameters(),\n",
        "\tlr=0.001,\n",
        "\tweight_decay=0.0005,\n",
        "\tmomentum=0.9,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hD92eoT-j6D"
      },
      "source": [
        "Train the model, batch by batch, for as many iterations as required to converge. You can use the validation set to determine automatically when to stop training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EnKf_P2F-j6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NubrrNxS-j6D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNTFZeQp-j6D"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Evaluate patch-based accuracy on the test set; then using the test patch coordinates, piece together the segmentation prediction on the original TIF images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ti-jbJN_-j6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Nl9AAl2Y-j6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZKi9gWgN-j6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}