{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolarHack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJSOnOXPzejUPxCrLz7PZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pahdsn/ati_sense_hackathon/blob/master/HarryCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0jnNBWOqBoI",
        "outputId": "4343f9df-30e0-4d9d-d10c-21f37803fbb6"
      },
      "source": [
        "# Installations\r\n",
        "\r\n",
        "!pip install geopandas\r\n",
        "!pip install rasterio"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/9f/e8a440a993e024c0d3d4e5c7d3346367c50c9a1a3d735caf5ee3bde0aab1/geopandas-0.8.2-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c2/67d1d0acbaaee3b03e5e22e3b96c33219cb5dd392531c9ff9cee7c2eb3e4/Fiona-1.8.18-cp37-cp37m-manylinux1_x86_64.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 323kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/0c/d7c2c7c370ea5368b813a44e772247ed1a461dc47de70c5d02e079abc7e0/pyproj-3.0.0.post1-cp37-cp37m-manylinux2010_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (20.3.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (1.19.5)\n",
            "Installing collected packages: click-plugins, cligj, munch, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.18 geopandas-0.8.2 munch-2.5.0 pyproj-3.0.0.post1\n",
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/ed/aa7cc593dbcb974f80ca0a15967d44abc820dbeb063e01478c95adcca156/rasterio-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 259kB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2020.12.5)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (20.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.3.0 rasterio-1.2.0 snuggs-1.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hipR-oeqmYA"
      },
      "source": [
        "# Imports\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import geopandas as gpd\r\n",
        "import pandas as pd\r\n",
        "import rasterio\r\n",
        "import os\r\n",
        "import glob\r\n",
        "from google.colab import drive\r\n",
        "import gdal\r\n",
        "from shapely.geometry import Point\r\n",
        "from PIL import Image\r\n",
        "from tqdm import tqdm\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import transforms\r\n",
        "import torch\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuygRzXXqpjW",
        "outputId": "63b6c25d-d5b2-4d15-aec8-b205f397f311"
      },
      "source": [
        "# Mount Drive and set up paths\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "os.chdir('/content/drive/My Drive/Polar_Hack')\r\n",
        "SAMPLING_DIR = \"./samples/\"\r\n",
        "META_DIR = \"./samples_meta/\"\r\n",
        "SHAPEFILE_DIR = \"./EE_Polar_Training_Dataset_v-1-0-0/Sea_Ice/\" \r\n",
        "TIFF_DIR = \"./Sentinel geotiffs/\"\r\n",
        "\r\n",
        "shapefiles = glob.glob(SHAPEFILE_DIR+'*.shp')\r\n",
        "images = glob.glob(TIFF_DIR+'*.tif')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaG0AkhHq90r"
      },
      "source": [
        "# Define routine for extracting label on subset of image\r\n",
        "\r\n",
        "def get_id(shapefile):\r\n",
        "  '''\r\n",
        "  Extracts datetime component of name\r\n",
        "  '''\r\n",
        "  return shapefile.split(\"_\")[-1][:-4].upper()\r\n",
        "\r\n",
        "def geo_ref(x,y,GT):\r\n",
        "  '''\r\n",
        "  return georeferenced point from pixel coordinates\r\n",
        "  '''\r\n",
        "  X_geo = GT[0] + x * GT[1] + y * GT[2]\r\n",
        "  Y_geo = GT[3] + x * GT[4] + y * GT[5]\r\n",
        "  return Point(X_geo, Y_geo)\r\n",
        "\r\n",
        "def sample(shapefile,x,y,N):\r\n",
        "  '''\r\n",
        "  Find tiff file, create NxN sample with origin (x,y) in pixel coordinates\r\n",
        "  Return id, sample and class from shapefile\r\n",
        "  '''\r\n",
        "  id = get_id(shapefile)\r\n",
        "  shape_data = gpd.read_file(shapefile)\r\n",
        "  tiff =  gdal.Open([g for g in images if id in g][0])\r\n",
        "  point = geo_ref(x+N/2,y+N/2,tiff.GetGeoTransform())\r\n",
        "  i=0\r\n",
        "  classification = None\r\n",
        "  while i < shape_data.shape[0] and classification == None:\r\n",
        "    if shape_data['geometry'][i].contains(point):\r\n",
        "      classification = shape_data['poly_type'][i]\r\n",
        "    i += 1\r\n",
        "  if classification != None:\r\n",
        "    im = Image.fromarray(np.transpose(tiff.ReadAsArray()[:,x:x+N,y:y+N],(1,2,0)))\r\n",
        "    image_name = SAMPLING_DIR+id+'X'+str(x)+'Y'+str(y)+'.png'\r\n",
        "    im.save(image_name)\r\n",
        "    return id, classification, image_name\r\n",
        "  else:\r\n",
        "    return None, None, None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjIICGLC7y7O"
      },
      "source": [
        "# Raw image dimensions\r\n",
        "xx = 15564\r\n",
        "yy = 15218\r\n",
        "\r\n",
        "def get_samples(grid_space, sample_size):\r\n",
        "  '''\r\n",
        "  Grid space - how densely to sample the raw S1 images\r\n",
        "  sample size - size of square sample images (both in pixels)\r\n",
        "  Saves sample images in png format and metadata as csv file\r\n",
        "  '''\r\n",
        "  metadata = pd.DataFrame(columns=['id','x','y','label','image'])\r\n",
        "  for S in tqdm(shapefiles):\r\n",
        "    for x in np.arange(2*grid_space,xx-2*grid_space,grid_space):\r\n",
        "      for y in np.arange(2*grid_space,yy-2*grid_space,grid_space):\r\n",
        "        id, label, name = sample(S,x,y,sample_size)\r\n",
        "        if label != None:\r\n",
        "          metadata = metadata.append({'id':id,'x':x,'y':y,'label':label,'image':name},ignore_index=True)\r\n",
        "    metadata.to_csv(META_DIR+'samples.csv')\r\n",
        "  return metadata"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "KCOR5ryW_K8h",
        "outputId": "f30cd2c2-fcd1-4896-e83c-bc4d67e2df95"
      },
      "source": [
        "LABELS = {\r\n",
        "\t\"L\": 0,\r\n",
        "\t\"W\": 1,\r\n",
        "\t\"I\": 2,\r\n",
        "}\r\n",
        "samples = pd.read_csv(META_DIR+'samples.csv',usecols=['id','x','y','label','image'])\r\n",
        "samples['label'] = [LABELS.get(ll) for ll in samples['label']]\r\n",
        "samples.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>label</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>1500</td>\n",
              "      <td>9000</td>\n",
              "      <td>0</td>\n",
              "      <td>./samples/20180814T075344X1500Y9000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>1500</td>\n",
              "      <td>9500</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X1500Y9500.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>8000</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y8000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>8500</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y8500.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>9000</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y9000.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id     x     y  label                                    image\n",
              "0  20180814T075344  1500  9000      0  ./samples/20180814T075344X1500Y9000.png\n",
              "1  20180814T075344  1500  9500      2  ./samples/20180814T075344X1500Y9500.png\n",
              "2  20180814T075344  2000  8000      2  ./samples/20180814T075344X2000Y8000.png\n",
              "3  20180814T075344  2000  8500      2  ./samples/20180814T075344X2000Y8500.png\n",
              "4  20180814T075344  2000  9000      2  ./samples/20180814T075344X2000Y9000.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Hj-rpXEPvv",
        "outputId": "b0bc691c-3bf9-4bfc-ff02-8338db33aa1d"
      },
      "source": [
        "samples.values\r\n",
        "\r\n",
        "# valid size = 1.0 - TRAIN_SIZE"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['20180814T075344', 1500, 9000, 0],\n",
              "       ['20180814T075344', 1500, 9500, 2],\n",
              "       ['20180814T075344', 2000, 8000, 2],\n",
              "       ...,\n",
              "       ['20180213T175444', 14500, 11500, 1],\n",
              "       ['20180213T175444', 14500, 12000, 1],\n",
              "       ['20180213T175444', 14500, 12500, 1]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkee63SCFFvL"
      },
      "source": [
        "# Set up data for torch\r\n",
        "\r\n",
        "TRAIN_SIZE = 0.7\r\n",
        "\r\n",
        "class PolarPatch(Dataset):\r\n",
        "    '''\r\n",
        "    TorchUtils dataset\r\n",
        "    '''\r\n",
        "    def __init__(self, transform=None, split=\"train\"):\r\n",
        "        super(PolarPatch, self).__init__()\r\n",
        "\r\n",
        "        assert split in [\"train\", \"val\"]\r\n",
        "        \r\n",
        "        # TODO: load in meta data, which should be of shape (3, N) - N being the number of samples\r\n",
        "        meta = samples.values\r\n",
        "\r\n",
        "        train_dim = int(TRAIN_SIZE * len(meta))\r\n",
        "        \r\n",
        "        if split == \"train\":\r\n",
        "            meta = meta[:train_dim]\r\n",
        "        else:\r\n",
        "            meta = meta[train_dim:]                   \r\n",
        "        self.id = meta[0]\r\n",
        "        self.images = meta[4]\r\n",
        "        self.coords = [(row[1], row[2]) for row in meta]\r\n",
        "\r\n",
        "        # Targets in integer form for computing cross entropy\r\n",
        "        self.targets = meta[3]\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.targets)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "\r\n",
        "        x = Image.open(self.images[index]) # change this file format if needed\r\n",
        "        y = self.targets[index]\r\n",
        "        coord = self.coords[index]\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "        \tx = self.transform(x)\r\n",
        "\r\n",
        "        return x, y, coord\r\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiu21FMIM-pj"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "data_transform = transforms.Compose([\r\n",
        "    # TODO: add whatever else you need - normalisation, augmentation, etc.\r\n",
        "\ttransforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_set = PolarPatch(\r\n",
        "    split='train',\r\n",
        "    transform=data_transform\r\n",
        ")\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_set,\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=2\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqnI8IJhQyxm",
        "outputId": "f4403a4f-8b35-40ae-b24a-3de59e8a86ec"
      },
      "source": [
        "# nn i torch neural network class\r\n",
        "# Create a specific nn for our purposes called PolarNet\r\n",
        "\r\n",
        "class PolarNet(nn.Module): # nn.Module is base class for all networks\r\n",
        "    def __init__(self, n_classes=3):\r\n",
        "        super(PolarNet, self).__init__()\r\n",
        "# Super means inherit attributes, presumably from nn.Module\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            # TODO: build your own architecture here; one conv layer and ReLU here as an example only\r\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\r\n",
        "            nn.ReLU(inplace=True), \r\n",
        "        )\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            # TODO: continue classifier section of architecture here for classification approach;\r\n",
        "            # otherwise, remove and add in upscaling for a fully-convolutional segmentation approach \r\n",
        "            nn.Linear(4096, n_classes),\r\n",
        "        )      \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # as an example; alter as needed depending on your architecture\r\n",
        "        x = self.features(x)\r\n",
        "\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fdfb783c950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjZmQKe1RI-_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}