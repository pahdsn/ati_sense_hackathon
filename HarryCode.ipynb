{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PolarHack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1lzaWzeLj9xGP0uDk+Gz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pahdsn/ati_sense_hackathon/blob/master/HarryCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0jnNBWOqBoI",
        "outputId": "4343f9df-30e0-4d9d-d10c-21f37803fbb6"
      },
      "source": [
        "# Installations\r\n",
        "\r\n",
        "!pip install geopandas\r\n",
        "!pip install rasterio"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/9f/e8a440a993e024c0d3d4e5c7d3346367c50c9a1a3d735caf5ee3bde0aab1/geopandas-0.8.2-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Collecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c2/67d1d0acbaaee3b03e5e22e3b96c33219cb5dd392531c9ff9cee7c2eb3e4/Fiona-1.8.18-cp37-cp37m-manylinux1_x86_64.whl (14.8MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8MB 323kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/0c/d7c2c7c370ea5368b813a44e772247ed1a461dc47de70c5d02e079abc7e0/pyproj-3.0.0.post1-cp37-cp37m-manylinux2010_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (20.3.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/42/1e/947eadf10d6804bf276eb8a038bd5307996dceaaa41cfd21b7a15ec62f5d/cligj-0.7.1-py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->geopandas) (1.19.5)\n",
            "Installing collected packages: click-plugins, cligj, munch, fiona, pyproj, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.1 fiona-1.8.18 geopandas-0.8.2 munch-2.5.0 pyproj-3.0.0.post1\n",
            "Collecting rasterio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/ed/aa7cc593dbcb974f80ca0a15967d44abc820dbeb063e01478c95adcca156/rasterio-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (19.1MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1MB 259kB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2020.12.5)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Collecting affine\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/a6/1a39a1ede71210e3ddaf623982b06ecfc5c5c03741ae659073159184cd3e/affine-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (20.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.3.0 rasterio-1.2.0 snuggs-1.4.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hipR-oeqmYA"
      },
      "source": [
        "# Imports\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import geopandas as gpd\r\n",
        "import pandas as pd\r\n",
        "import rasterio\r\n",
        "import os\r\n",
        "import glob\r\n",
        "from google.colab import drive\r\n",
        "import gdal\r\n",
        "from shapely.geometry import Point\r\n",
        "from PIL import Image\r\n",
        "from tqdm import tqdm\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import transforms\r\n",
        "import torch\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuygRzXXqpjW",
        "outputId": "63b6c25d-d5b2-4d15-aec8-b205f397f311"
      },
      "source": [
        "# Mount Drive and set up paths\r\n",
        "\r\n",
        "drive.mount('/content/drive')\r\n",
        "os.chdir('/content/drive/My Drive/Polar_Hack')\r\n",
        "SAMPLING_DIR = \"./samples/\"\r\n",
        "META_DIR = \"./samples_meta/\"\r\n",
        "SHAPEFILE_DIR = \"./EE_Polar_Training_Dataset_v-1-0-0/Sea_Ice/\" \r\n",
        "TIFF_DIR = \"./Sentinel geotiffs/\"\r\n",
        "\r\n",
        "shapefiles = glob.glob(SHAPEFILE_DIR+'*.shp')\r\n",
        "images = glob.glob(TIFF_DIR+'*.tif')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaG0AkhHq90r"
      },
      "source": [
        "# Define routine for extracting label on subset of image\r\n",
        "\r\n",
        "def get_id(shapefile):\r\n",
        "  '''\r\n",
        "  Extracts datetime component of name\r\n",
        "  '''\r\n",
        "  return shapefile.split(\"_\")[-1][:-4].upper()\r\n",
        "\r\n",
        "def geo_ref(x,y,GT):\r\n",
        "  '''\r\n",
        "  return georeferenced point from pixel coordinates\r\n",
        "  '''\r\n",
        "  X_geo = GT[0] + x * GT[1] + y * GT[2]\r\n",
        "  Y_geo = GT[3] + x * GT[4] + y * GT[5]\r\n",
        "  return Point(X_geo, Y_geo)\r\n",
        "\r\n",
        "def sample(shapefile,x,y,N):\r\n",
        "  '''\r\n",
        "  Find tiff file, create NxN sample with origin (x,y) in pixel coordinates\r\n",
        "  Return id, sample and class from shapefile\r\n",
        "  '''\r\n",
        "  id = get_id(shapefile)\r\n",
        "  shape_data = gpd.read_file(shapefile)\r\n",
        "  tiff =  gdal.Open([g for g in images if id in g][0])\r\n",
        "  point = geo_ref(x+N/2,y+N/2,tiff.GetGeoTransform())\r\n",
        "  i=0\r\n",
        "  classification = None\r\n",
        "  while i < shape_data.shape[0] and classification == None:\r\n",
        "    if shape_data['geometry'][i].contains(point):\r\n",
        "      classification = shape_data['poly_type'][i]\r\n",
        "    i += 1\r\n",
        "  if classification != None:\r\n",
        "    im = Image.fromarray(np.transpose(tiff.ReadAsArray()[:,x:x+N,y:y+N],(1,2,0)))\r\n",
        "    image_name = SAMPLING_DIR+id+'X'+str(x)+'Y'+str(y)+'.png'\r\n",
        "    im.save(image_name)\r\n",
        "    return id, classification, image_name\r\n",
        "  else:\r\n",
        "    return None, None, None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjIICGLC7y7O"
      },
      "source": [
        "# Raw image dimensions\r\n",
        "xx = 15564\r\n",
        "yy = 15218\r\n",
        "\r\n",
        "def get_samples(grid_space, sample_size):\r\n",
        "  '''\r\n",
        "  Grid space - how densely to sample the raw S1 images\r\n",
        "  sample size - size of square sample images (both in pixels)\r\n",
        "  Saves sample images in png format and metadata as csv file\r\n",
        "  '''\r\n",
        "  metadata = pd.DataFrame(columns=['id','x','y','label','image'])\r\n",
        "  for S in tqdm(shapefiles):\r\n",
        "    for x in np.arange(2*grid_space,xx-2*grid_space,grid_space):\r\n",
        "      for y in np.arange(2*grid_space,yy-2*grid_space,grid_space):\r\n",
        "        id, label, name = sample(S,x,y,sample_size)\r\n",
        "        if label != None:\r\n",
        "          metadata = metadata.append({'id':id,'x':x,'y':y,'label':label,'image':name},ignore_index=True)\r\n",
        "    metadata.to_csv(META_DIR+'samples.csv')\r\n",
        "  return metadata"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "KCOR5ryW_K8h",
        "outputId": "f30cd2c2-fcd1-4896-e83c-bc4d67e2df95"
      },
      "source": [
        "LABELS = {\r\n",
        "\t\"L\": 0,\r\n",
        "\t\"W\": 1,\r\n",
        "\t\"I\": 2,\r\n",
        "}\r\n",
        "samples = pd.read_csv(META_DIR+'samples.csv',usecols=['id','x','y','label','image'])\r\n",
        "samples['label'] = [LABELS.get(ll) for ll in samples['label']]\r\n",
        "samples.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>label</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>1500</td>\n",
              "      <td>9000</td>\n",
              "      <td>0</td>\n",
              "      <td>./samples/20180814T075344X1500Y9000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>1500</td>\n",
              "      <td>9500</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X1500Y9500.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>8000</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y8000.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>8500</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y8500.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20180814T075344</td>\n",
              "      <td>2000</td>\n",
              "      <td>9000</td>\n",
              "      <td>2</td>\n",
              "      <td>./samples/20180814T075344X2000Y9000.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id     x     y  label                                    image\n",
              "0  20180814T075344  1500  9000      0  ./samples/20180814T075344X1500Y9000.png\n",
              "1  20180814T075344  1500  9500      2  ./samples/20180814T075344X1500Y9500.png\n",
              "2  20180814T075344  2000  8000      2  ./samples/20180814T075344X2000Y8000.png\n",
              "3  20180814T075344  2000  8500      2  ./samples/20180814T075344X2000Y8500.png\n",
              "4  20180814T075344  2000  9000      2  ./samples/20180814T075344X2000Y9000.png"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Hj-rpXEPvv",
        "outputId": "6ab59f15-f7f6-48e5-ee66-1312b641dbf3"
      },
      "source": [
        "samples.values[:,4]\r\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['./samples/20180814T075344X1500Y9000.png',\n",
              "       './samples/20180814T075344X1500Y9500.png',\n",
              "       './samples/20180814T075344X2000Y8000.png', ...,\n",
              "       './samples/20180213T175444X14500Y11500.png',\n",
              "       './samples/20180213T175444X14500Y12000.png',\n",
              "       './samples/20180213T175444X14500Y12500.png'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkee63SCFFvL"
      },
      "source": [
        "# Set up data for torch\r\n",
        "\r\n",
        "TRAIN_SIZE = 0.7\r\n",
        "\r\n",
        "class PolarPatch(Dataset):\r\n",
        "    '''\r\n",
        "    TorchUtils dataset\r\n",
        "    '''\r\n",
        "    def __init__(self, transform=None, split=\"train\"):\r\n",
        "        super(PolarPatch, self).__init__()\r\n",
        "\r\n",
        "        assert split in [\"train\", \"val\"]\r\n",
        "        \r\n",
        "        # TODO: load in meta data, which should be of shape (3, N) - N being the number of samples\r\n",
        "        meta = samples.values\r\n",
        "\r\n",
        "        train_dim = int(TRAIN_SIZE * len(meta))\r\n",
        "        \r\n",
        "        if split == \"train\":\r\n",
        "            meta = meta[:train_dim]\r\n",
        "        else:\r\n",
        "            meta = meta[train_dim:]                   \r\n",
        "        self.images = meta[:,4]\r\n",
        "        self.coords = [(row[1], row[2]) for row in meta]\r\n",
        "\r\n",
        "        # Targets in integer form for computing cross entropy\r\n",
        "        self.targets = meta[:,3]\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.targets)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "\r\n",
        "        x = Image.open(self.images[index]) # change this file format if needed\r\n",
        "        y = self.targets[index]\r\n",
        "        coord = self.coords[index]\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "        \tx = self.transform(x)\r\n",
        "\r\n",
        "        return x, y, coord\r\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiu21FMIM-pj"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "data_transform = transforms.Compose([\r\n",
        "    # TODO: add whatever else you need - normalisation, augmentation, etc.\r\n",
        "\ttransforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_set = PolarPatch(\r\n",
        "    split='train',\r\n",
        "    transform=data_transform\r\n",
        ")\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_set,\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=True,\r\n",
        "    num_workers=2\r\n",
        ")\r\n",
        "\r\n",
        "test_set = PolarPatch(\r\n",
        "    split='val',\r\n",
        "    transform=data_transform\r\n",
        ")\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    test_set,\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=False,\r\n",
        "    num_workers=2\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqnI8IJhQyxm"
      },
      "source": [
        "# nn i torch neural network class\r\n",
        "# Create a specific nn for our purposes called PolarNet\r\n",
        "\r\n",
        "class PolarNet(nn.Module): # nn.Module is base class for all networks\r\n",
        "    def __init__(self, n_classes=3):\r\n",
        "        super(PolarNet, self).__init__()\r\n",
        "# Super means inherit attributes, presumably from nn.Module\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            # TODO: build your own architecture here; one conv layer and ReLU here as an example only\r\n",
        "            nn.Conv2d(3, 16, kernel_size=5, padding=0),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=2),\r\n",
        "            nn.Conv2d(16,64,kernel_size=5,padding=0),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=2)\r\n",
        "        ) # 13*13 * 64 = 10816 pixels\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Linear(10816,36),\r\n",
        "            nn.ReLU(), \r\n",
        "            nn.Linear(36, 3)\r\n",
        "        )      \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # as an example; alter as needed depending on your architecture\r\n",
        "        x = self.features(x)\r\n",
        "\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjZmQKe1RI-_"
      },
      "source": [
        "# Device configuration - defaults to CPU unless GPU is available on device\r\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "model = PolarNet().to(DEVICE)\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Stochastic Gradient Descent\r\n",
        "optimizer = torch.optim.SGD(\r\n",
        "\tmodel.parameters(),\r\n",
        "\tlr=0.001,\r\n",
        "\tweight_decay=0.0005,\r\n",
        "\tmomentum=0.9,\r\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS-8RUILgePp"
      },
      "source": [
        "'''\r\n",
        "David Hogg's functions (modified) for capturing the stats during training\r\n",
        "'''\r\n",
        "\r\n",
        "def stats(loader, net):\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    running_loss = 0\r\n",
        "    n = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data in loader:\r\n",
        "            images, labels, coords = data\r\n",
        "            images = images.to(DEVICE)\r\n",
        "            labels = labels.to(DEVICE)\r\n",
        "            outputs = net.forward(images)\r\n",
        "            loss = loss_fn(outputs, labels)\r\n",
        "            _, predicted = torch.max(outputs.data, 1)\r\n",
        "            total += labels.size(0)    # add in the number of labels in this minibatch\r\n",
        "            correct += (predicted == labels).sum().item()  # add in the number of correct labels\r\n",
        "            running_loss += loss\r\n",
        "            n += 1\r\n",
        "    return running_loss/n, correct/total \r\n",
        "\r\n",
        "def statsplot(statsrec):\r\n",
        "    fig, ax1 = plt.subplots()\r\n",
        "    plt.plot(statsrec[0], 'r', label = 'training loss', )\r\n",
        "    plt.plot(statsrec[1], 'g', label = 'test loss' )\r\n",
        "    plt.legend(loc='center')\r\n",
        "    plt.xlabel('epoch')\r\n",
        "    plt.ylabel('loss')\r\n",
        "    plt.title('Training and test loss, and test accuracy')\r\n",
        "    ax2=ax1.twinx()\r\n",
        "    ax2.plot(statsrec[2], 'b', label = 'test accuracy')\r\n",
        "    ax2.set_ylabel('accuracy')\r\n",
        "    plt.legend(loc='upper left')\r\n",
        "    plt.show()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DIScPmLgQRQ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYxgRRlhfnuH",
        "outputId": "574de9b7-2b03-4652-9b27-fafb2a91e602"
      },
      "source": [
        "nepochs = 10\r\n",
        "# How many times go through the full training dataset\r\n",
        "\r\n",
        "statsrec = np.zeros((3,nepochs))\r\n",
        "# Numy array for holding some results\r\n",
        "\r\n",
        "for epoch in range(nepochs):  # loop over the dataset multiple times\r\n",
        "\r\n",
        "    running_loss = 0.0\r\n",
        "    n = 0\r\n",
        "    for i, data in enumerate(train_loader, 0):\r\n",
        "        inputs, labels, coords = data\r\n",
        "        inputs = inputs.to(DEVICE)\r\n",
        "        labels = labels.to(DEVICE)\r\n",
        "         # Zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # Forward, backward, and update parameters\r\n",
        "        outputs = model.forward(inputs)\r\n",
        "        loss = loss_fn(outputs, labels)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "    \r\n",
        "        # accumulate loss\r\n",
        "        running_loss += loss.item()\r\n",
        "        n += 1\r\n",
        "    \r\n",
        "    ltrn = running_loss/n\r\n",
        "    ltst, atst = stats(test_loader, model)\r\n",
        "    statsrec[:,epoch] = (ltrn, ltst, atst)\r\n",
        "    print(f\"epoch: {epoch} training loss: {ltrn: .3f}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\r\n",
        "\r\n",
        "print('********** Finished Training ***************')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 training loss:  0.848  test loss:  1.075 test accuracy:  38.4%\n",
            "epoch: 1 training loss:  0.793  test loss:  1.020 test accuracy:  40.6%\n",
            "epoch: 2 training loss:  0.726  test loss:  0.919 test accuracy:  52.0%\n",
            "epoch: 3 training loss:  0.653  test loss:  0.868 test accuracy:  55.3%\n",
            "epoch: 4 training loss:  0.596  test loss:  0.876 test accuracy:  56.2%\n",
            "epoch: 5 training loss:  0.563  test loss:  0.871 test accuracy:  62.8%\n",
            "epoch: 6 training loss:  0.547  test loss:  0.886 test accuracy:  57.1%\n",
            "epoch: 7 training loss:  0.545  test loss:  0.863 test accuracy:  63.8%\n",
            "epoch: 8 training loss:  0.537  test loss:  0.852 test accuracy:  66.8%\n",
            "epoch: 9 training loss:  0.533  test loss:  0.847 test accuracy:  69.5%\n",
            "********** Finished Training ***************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpkyJfWh4Ru",
        "outputId": "0f6619ce-b34f-4eab-eff7-8b1d602fd9c6"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              " \n",
              "         [[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          ...,\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]],\n",
              " \n",
              "         [[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          ...,\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]]),\n",
              " 0,\n",
              " (1500, 9000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}